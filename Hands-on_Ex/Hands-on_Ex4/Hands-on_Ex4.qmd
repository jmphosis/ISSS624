---
title: "Hands-on Exercise 4"
date: "6 December 2023"
format: html
execute: 
  echo: true #shows the code
  eval: true #shows the outcomes of the code
  warning: false #does not show the warnings
editor: visual
background-color: lightgrey;
font-family:  Palatino Linotype;
---

# 13 Calibrating Hedonic Pricing Model for Private High-rise Property with Geographically Weighted Regression (GWR) Method

## 13.1 Overview

**Geographically Weighted Regression (GWR)** is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate, demographic factors, physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable).

In this hands-on exercise, hedonic pricing models are built using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural or locational factors.

## 13.2 The Data

The two data sets used in this hand-on exercise are:

1.  URA Master Plan Subzone Boundary in shapefile format (i.e. *MP14_SUBZONE_WEB_PL*); and

2.  2015 Condo Resale Data in csv format (i.e. *condo_resale_2015.csv*).

## 13.3 Getting Started

The packages used in this hands-on exercise are:

-   **sf** for spatial data handling;

-   **tidyverse** for attribute data handling;

-   **tmap** for choropleth mapping;

-   **ggpubr** for creating customised and annotated ggplot2 plots for better visualisation;

-   **corrplot** for multivariate data visualisation and analysis;

-   **spdep** for analysing spatial dependence and spatial relationships in data;

-   **GWmodel** for calibrating geographical weighted family of models;

-   **olsrr** for building ordinary least squares (OLS) regression models and performing diagnostic tests; and

-   **gtsummary** for creating publication-ready analytical and summary tables;

The packages are loaded into the R environment:

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)
```

[GWModel Package]{.underline}

The GWmodel package provides a collection of localised spatial statistical methods, namely:

-   Geographically weighted summary statistics,

-   Geographically weighted principal components analysis,

-   Geographically weighted discriminant analysis, and

-   Various forms of geographically weighted regression, some of which are provided in basic and robust (outlier resistant) forms.

Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.

## 13.4 Geospatial Data Wrangling

### 13.4.1 Importing Geospatial Data

The geospatial data used in this hands-on exercise is *MP14_SUBZONE_WEB_PL*. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014's planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in SVY21 projected coordinates systems.

The `st_read()` function in the **sf** package is used to import the shapefile as `mpsz`, a simple feature object.

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

### 13.4.2 Updating CRS Information

The mpsz is transformed using the `st_transform()` function in the **sf** package to assign the correct ESPG code (i.e., 3414). This is then verified using the `st_crs()` function in the **sf** package.

```{r}
mpsz_svy21 = st_transform(mpsz, 3414)
st_crs(mpsz_svy21)
```

The extent of `mpsz_svy21` is revealed using the `st_bbox()` function in the **sf** package.

```{r}
st_bbox(mpsz_svy21)
```

## 13.5 Aspatial Data Wrangling

### 13.5.1 Importing Aspatial Data

The *condo_resale_2015* is a csv file. The `read_csv()` function in the **readr** package is used to import it as `condo_resale`, a tibble data frame.

```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
```

The `glimpse()` function in the **dplyr** package, the head() function and the summary() function in the base package are used to take a preliminary look at and derive the summary statistics of `condo_resale`.

```{r}
glimpse(condo_resale)
```

```{r}
head(condo_resale$LONGITUDE) #see the data in XCOORD column
```

```{r}
head(condo_resale$LATITUDE) #see the data in YCOORD column
```

```{r}
summary(condo_resale)
```

### 13.5.2 Converting Aspatial Data Frame into a Simple Feature Object

The `st_as_sf()` function in the **sf** package is used to convert the aspatial tibble data frame, condo_resale, into a simple feature object.

Notice that the `st_transform()` function in the sf package is used to convert the coordinates from WGS84 (i.e. CRS = 4326) to SVY21 (i.e. CRS = 3414).

```{r}
condo_resale.sf = st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)
```

The `head()` function is used to list the content of condo_resale.sf object, which is a point feature data frame.

```{r}
head(condo_resale.sf)
```

## 13.6 Exploratory Data Analysis (EDA)

The statistical graphics functions in the **ggplot2** package are used to perform exploratory data analysis.

### 13.6.1 Exploratory Data Analysis (EDA) Using Statistical Graphics

The distribution of "SELLING_PRICE" is plotted in a histogram. The histogram reveals a right skewed distribution. This means that more condominium units were transacted at relatively lower prices.

```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

Statistically, the skewed dsitribution can be normalised by using log transformation. The `mutate()` function in the **dplyr** package is used to derive a new variable, "LOG_SELLING_PRICE" from "SELLING_PRICE".

```{r}
condo_resale.sf = condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))
```

The histogram is then plotted using "LOG_SELLING_PRICE". The distribution is relatively less skewed after the log transformation.

```{r}
ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

### 13.6.2 Multiple Histograms Plots of Distribution of Variables

The `ggarrange()` function in the **ggpubr** package is used to draw a trellis plot of multiple small histograms of the various variables.

```{r}
AREA_SQM = ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

AGE = ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD = ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CHILDCARE = ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_ELDERLYCARE = ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_URA_GROWTH_AREA = ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER_MARKET = ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_KINDERGARTEN = ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT = ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK = ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PRIMARY_SCH = ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_TOP_PRIMARY_SCH = ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)
```

### 13.6.3 Drawing Statistical Point Map

The functions in the **tmap** package are used to show the geospatial distribution of condominium resale prices.

The `tm_dots()` function is used instead of the `tm_bubbles()` function because the former creates a simple dot plot for point data, while the latter allows each point to be represented as a bubble with a size corresponding to a variable.

The tm_view() function with the\
"set.zoom.limits" argument sets the minimum and maximum zoom levels to 11 and 14 respectively.

The tmap_options() function with argument "check.and.fix = TRUE" is helpful in preventing errors or unexpected behavior when creating maps, especially when dealing with complex spatial data sets. It helps ensure that the spatial objects are in a valid state for plotting.

```{r}
tmap_mode("view")
tmap_options(check.and.fix = TRUE)

tm_shape(mpsz_svy21)+
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style = "quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

The `tmap_mode()` function with "plot" argument is used to turn the display into the plot mode.

```{r}
tmap_mode("plot")
```

## 13.7 Hedonic Pricing Modelling in R

The hedonic pricing models for condominium resale units are built using the `lm()` function in the **stats** package.

### 13.7.1 Simple Linear Regression Method

A simple linear regression model is built using "SELLING_PRICE" as the dependent variable and "AREA_SQM" as the independent variable.

```{r}
condo.slr = lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

The `lm()` function returns an object of class "lm" or for multiple responses of class c("mlm,"lm").

The `summary()` function in the **base** package and the `anova()` in the **stats** package are used to obtain a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by the `lm()` function.

```{r}
summary(condo.slr)
```

The output shows that the "SELLING_PRICE" can be explained using the formula:

> SELLING_PRICE = -258121.1 + 14719\*AREA_SQM

The R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.

Since the p-value is much smaller than 0.0001, the null hypothesis is rejected, i.e., reject that there is no significant relationship between the independent variable and the dependent variable, and infer that the simple linear regression model is a good estimator of "SELLING_PRICE".

The coefficients section of the output reveals that the p-values of both the estimates of the Intercept and "AREA_SQM" are smaller than 0.001. Hence, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a result, it can be inferred that the B0 and B1 are good parameter estimates.

The ggplot() function is used to draw a scatterplot to visualise the best fit line using the `lm()` method. There are a few statistical outliers with relatively high selling prices.

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```

### 13.7.2 Multiple Linear Regression Method

[Visualising the Relationships of Independent Variables]{.underline}

Before building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If highly correlated independent variables are used in building a regression model, the quality of the model will be compromised. This phenomenon is known as **multicollinearity** in statistics.

A correlation matrix is commonly used to visualise the relationships between the independent variables. Beside the `pairs()` function in the **graphics** package, there are many packages that support the display of a correlation matrix. In this hands-on exercise, the **corrplot** package will be used.

```{r}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

The matrix reorder is very important for mining the hidden structure and pattern in the matrix. There are four methods in **corrplot** (parameter order), named "AOE", "FPC", "hclust", "alphabet". In the code chunk above, "AOE" order is used. It orders the variables by using the *angular order of the eigenvectors* method. From the scatterplot matrix, it is clear that "Freehold" is highly correlated to "LEASE_99YEAR". In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, the latter is excluded in the subsequent model building.

### 13.7.3 Building a Hedonic Pricing Model Using Multiple Linear Regression Method

The `lm()` function is used to calibrate the multiple linear regression model.

```{r}
condo.mlr = lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)
summary(condo.mlr)
```

### 13.7.4 Preparing Publication Quality Table Using olsrr Package

From the output above, it is clear that not all the independent variables are statistically significant. The model is revised by removing variables which are not statistically significant.

> ***Student Note***: The four variables removed are: "PROX_HAWKER_MARKET", "PROX_KINDERGARTEN", "PROX_TOP_PRIMARY_SCH", and "PROX_SUPERMARKET"

```{r}
condo.mlr1 = lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)
ols_regress(condo.mlr1)
```

### 13.7.5 Preparing Publication Quality Table Using gtsummary Package

The **gtsummary** package provides an elegant and flexible way to create publication-ready summary tables. The `tbl_regression()` function is used to create a well formatted regression report.

```{r}
tbl_regression(condo.mlr1, intercept = TRUE)
```

With **gtsummary** package, model statistics can be included in the report by either appending them to the report table by using the `add_glance_table()` function or adding as a table source note by using the `add_glance_source_note()` function.

```{r}
tbl_regression(condo.mlr1, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

#### 13.7.5.1 Checking for Multicolinearity

The **oslrr** package is specially programmed for performing Ordinary Least Squares (OLS) regression. It provides a collection of very useful methods for building better multiple linear regression models:

-   Comprehensive regression output,

-   Residual diagnostics,

-   Measures of influence,

-   Heteroskedasticity tests,

-   Collinearity diagnostics,

-   Model fit assessment,

-   Variable contribution assessment, and

-   Variable selection procedures.

The `ols_vif_tol()` function in the **olsrr** package is used to test if there are signs of multicollinearity. Since the VIF of the independent variables are less than 10, it can be concluded that there are no signs of multicollinearity among the independent variables.

```{r}
ols_vif_tol(condo.mlr1)
```

#### 13.7.5.2 Test for Non-linearity

In multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.

The `ols_plot_resid_fit()` function in the **olsrr** package is used to perform linearity assumption test. The plot shows that most of the data points are scattered around the residual = 0 line. Hence, it can be concluded that the relationships between the dependent variable and independent variables are linear.

```{r}
ols_plot_resid_fit(condo.mlr1)
```

#### 13.7.5.3 Test for Normality Assumption

The `ols_plot_resid_hist()` function of the **olsrr** package is used to perform the normality assumption test of the residuals. The plot reveals that the residuals of the multiple linear regression model resemble normal distribution.

```{r}
ols_plot_resid_hist(condo.mlr1)
```

Alternatively, the `ols_test_normality()` function in the **olsrr** package is used to conduct a formal statistical test for the normality assumption. The summary table reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence, the null hypothesis is rejected, and it can be inferred that there is statistical evidence that the residuals are not normally distributed.

```{r}
ols_test_normality(condo.mlr1)
```

#### 13.7.5.4 Test for Spatial Autocorrelation

As the hedonic model uses geographically referenced attributes, it is also important to visualise the residual of the hedonic pricing model.

The `condo_resale.sf` simple feature data frame is converted into a SpatialPointsDataFrame in order to perform a spatial autocorrelation test.

The residual of the hedonic pricing model is exported and saved as a data frame.

```{r}
mlr.output = as.data.frame(condo.mlr1$residuals)
```

The `mlr.output` data frame is then joined with the `condo_resale.sf` simple feature data frame.

```{r}
condo_resale.res.sf = cbind(condo_resale.sf,                          condo.mlr1$residuals) %>% rename(`MLR_RES` = `condo.mlr1.residuals`)
```

The `condo_resale.res.sf` simple feature data frame is converted to SpatialPointsDataFrame (because the **spdep** package can only process sp conformed spatial data objects).

```{r}
condo_resale.sp = as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

The functions in the **tmap** package are used to display the distribution of the residuals on an interactive map. The plot reveals that there is sign of spatial autocorrelation.

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```

To test the observation, the Moran's I test is performed.

-   The `dnearneigh()` function in the **spdep** package is used to compute the distance-based weight matrix.

-   The `nb2listw()` function in the **spdep** package is used to convert the output neighbours lists (i.e., nb) into a list of spatial weights.

-   The `lm.morantest()` function in the **spdep** package is used to perform Moran's I test for residual spatial autocorrelation. The Global Moran's I test for residual spatial autocorrelation shows that it's p-value is less than 2.2e-16, which is less than the alpha value of 0.05. Hence, the null hypothesis is rejected, and it is inferred that the residuals are not randomly distributed. Since the observed global Moran I = 0.1424418 is greater than 0, it can be inferred that the residuals resemble cluster distribution.

```{r}
nb = dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

```{r}
nb_lw = nb2listw(nb, style = 'W')
summary(nb_lw)
```

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

## 13.8 Building Hedonic Pricing Models using GWModel

Hedonic pricing models are built using both the fixed and adaptive bandwidth schemes.

### 13.8.1 Building Fixed Bandwidth Geographically Weighted Regression (GWR) Model

#### 13.8.1.1 Computing Fixed Bandwidth

The `bw.gwr()` function in the **GWModel** package is used to determine the optimal fixed bandwidth to use in the model. The "adaptive = FALSE" argument meant that fixed bandwidth is used instead.

The two possible inputs for the "approach" argument that can be used to determine the stopping rule are:

1.  Cross-validation (CV) approach, and

2.  Akaike information criterion corrected (AICc) approach.

The output shows that the recommended bandwidth is 971.3405 metres.

```{r}
 bw.fixed = bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                     FAMILY_FRIENDLY + FREEHOLD, 
                   data=condo_resale.sp, 
                   approach="CV", 
                   kernel="gaussian", 
                   adaptive=FALSE, 
                   longlat=FALSE)
```

#### 13.8.1.2 Constructing Fixed Bandwidth Geographically Weighted Regression (GWR) Model

The GWR model using fixed bandwidth and Gaussian kernel is calibrated using the `gwr.basic()` function in the **GWmodel** package.

The output is saved in a list of class "gwrm", which shows that the AICc of the GWR is 42263.61 which is significantly smaller than that of the global multiple linear regression model of 42967.14.

```{r}
gwr.fixed = gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                         FAMILY_FRIENDLY + FREEHOLD, 
                       data=condo_resale.sp, 
                       bw=bw.fixed, 
                       kernel = 'gaussian', 
                       longlat = FALSE)

gwr.fixed
```

### 13.8.2 Building Adaptive Bandwidth Geographically Weighted Regression (GWR) Model

#### 13.8.2.1 Computing Adaptive Bandwidth

The `bw.gwr()` function in the **GWModel** package is used to determine the optimal adaptive bandwidth to use in the model. The "adaptive = TRUE" argument meant that adaptive bandwidth is used. The output shows that 30 is the recommended data points to be used.

```{r}
bw.adaptive = bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + 
                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + 
                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + 
                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                      data=condo_resale.sp, 
                      approach="CV", 
                      kernel="gaussian", 
                      adaptive=TRUE, 
                      longlat=FALSE)
```

#### 13.8.2.2 Constructing Adaptive Bandwidth Geographically Weighted Regression (GWR) Model

The GWR model using adaptive bandwidth and Gaussian kernel is calibrated using the `gwr.basic()` function in the **GWmodel** package.

The output is saved in a list of class "gwrm", which shows that the AICc of the GWR is 41982.22 which is significantly smaller than that of the global multiple linear regression model of 42967.14 and also smaller than that of the fixed distance GWR of 42263.61.

```{r}
gwr.adaptive = gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                          data=condo_resale.sp, bw=bw.adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE, 
                          longlat = FALSE)

gwr.adaptive
```

### 13.8.3 Visualising Geographically Weighted Regression (GWR) Output

In addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:

-   **Condition Number**: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.

-   **Local R2**: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.

-   **Predicted**: these are the estimated (or fitted) y values computed by GWR.

-   **Residuals**: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardised residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardised residuals can be produced by using these values.

-   **Coefficient Standard Error**: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.

They are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its "data" slot in an object called **SDF** of the output list.

### 13.8.4 Converting SDF into Simple Feature Data Frame

The SDF is converted into a simple feature data frame to visualise its fields.

```{r}
condo_resale.sf.adaptive = st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r}
condo_resale.sf.adaptive.svy21 = st_transform(condo_resale.sf.adaptive, 3414)
condo_resale.sf.adaptive.svy21  
```

```{r}
gwr.adaptive.output = as.data.frame(gwr.adaptive$SDF)

condo_resale.sf.adaptive = cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))
```

```{r}
glimpse(condo_resale.sf.adaptive)
```

```{r}
summary(gwr.adaptive$SDF$yhat)
```

### 13.8.5 Visualising Local R2

The local R2 values are visualised using the functions in the **tmap** package.

> ***Student Note***: The higher local R2 values for east (Changi, Simei), west (Jurong, Bukit Batok) and central (Orchard) regions indicate that the local regression model fits the observed y values. The lower local R2 values in the central region (Balestier, Toa Payoh, Bishan) indicate that the local regression model does not fit the observed y values as well. There could be other important variables determining resale selling prices in these areas.

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```

[By URA Planning Region]{.underline}

```{r}
tm_shape(mpsz_svy21[mpsz_svy21$REGION_N=="CENTRAL REGION", ]) +   tm_polygons()+ 
  tm_shape(condo_resale.sf.adaptive) +    
  tm_bubbles(col = "Local_R2",            
             size = 0.15,            
             border.col = "gray60",            
             border.lwd = 1)
```

## 

### 13.8.6 Visualising Coefficient Estimates

The coefficient estimates are visualised using the functions in the **tmap** package.

> ***Student Note***: The standard error values and t-values for "AREA_SQM" are mapped below.
>
> -   In the context of GWR, t-values are commonly associated with coefficient estimates. Each coefficient estimate has an associated standard error, and the t-value is calculated by dividing the coefficient estimate by its standard error. The resulting t-value is then compared to critical values from a t-distribution to assess whether the coefficient is statistically significant.
>
> -   In general, if the t-value is large (far from zero), it suggests that the coefficient estimate is significantly different from zero. If the t-value is small, it suggests that the coefficient estimate is not significantly different from zero.

```{r}
tmap_mode("view")
AREA_SQM_SE = tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_SE",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

AREA_SQM_TV = tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_TV",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, 
             asp=1, ncol=2,
             sync = TRUE)
```

## 13.9 References

Gollini I, Lu B, Charlton M, Brunsdon C, Harris P (2015) "GWmodel: an R Package for exploring Spatial Heterogeneity using Geographically Weighted Models". *Journal of Statistical Software*, 63(17):1-50, http://www.jstatsoft.org/v63/i17/

Lu B, Harris P, Charlton M, Brunsdon C (2014) "The GWmodel R Package: further topics for exploring Spatial Heterogeneity using GeographicallyWeighted Models". *Geo-spatial Information Science* 17(2): 85-101, http://www.tandfonline.com/doi/abs/10.1080/1009502.2014.917453

[**\~\~\~ End of Hands-on Exercise 4 \~\~\~**]{.smallcaps}
