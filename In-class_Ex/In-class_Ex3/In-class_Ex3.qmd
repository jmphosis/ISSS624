---
title: "In-class Exercise 3"
date: "2 December 2023"
date-modified: "last-modified" #allows for updating to the latest date
format: html
execute: 
  echo: true #shows the code
  eval: true #shows the outcomes of the code
  warning: false #does not show the warnings
editor: visual
background-color: lightgrey;
font-family:  Palatino Linotype;
---

# 16 Calibrating Spatial Interaction Models with R

## 16.1 Overview

Spatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities. They were developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then (Boyce and Williams, 2015).

There are four main types of traditional SIMs (Wilson 1971):

-   Unconstrained

-   Production-constrained

-   Attraction-constrained

-   Doubly-constrained

Ordinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables.

In this in-class exercise, the appropriate R packages are used to calibrate SIM by using there four regression methods.

***Note***: Calibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically, this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised or minimised (Adam Dennett, 2018).

## 16.2 The Case Study and Data

In this in-class exercise, a SIM is calibrated to determine the factors affecting the public bus passenger flows during the morning peak in Singapore.

## 16.3 Getting Started

For the purpose of this exercise, the following R packages are used:

-   **sf** for importing, integrating, processing and transforming geospatial data;

-   **tidyverse** for importing, integrating, wrangling and visualising data;

-   **tmap** for creating thematic maps;

-   **sp** for handling spatial data in computationally efficient ways;

-   **performance** for computing measures to assess model quality;

-   **reshape2** for handling matrix format; and

-   **ggpubr** for publication ready plots.

```{r}
pacman::p_load(tmap, sf, sp,
               performance, reshape2,
               ggpubr, tidyverse)
```

## 16.4 The Data

This exercise is a continuation of **Chapter 15: Processing and Visualising Flow Data** and the following data will be used:

-   `od_data.rds`: weekday morning peak passenger flows at planning subzone level.

-   `mpsz.rds`: URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.

Besides these two data sets, an additional attribute data file called `pop.csv` will be used.

## 16.5 Computing Distance Matrix

In spatial interaction, a distance matrix is a table that shows the distance between pairs of locations. For example, in the table below we can see an Euclidean distance of 3926.0025 between MESZ01 and RVSZ05, of 3939.1079 between MESZ01 and SRSZ01, and so on. By definition, an location's distance from itself, which is shown in the main diagonal of the table, is 0.

In this section,a distance matrix is computed by using the `mpsz`, which is first imported as a sf tibble dataframe object class.

```{r}
mpsz = read_rds("data/rds/mpsz.rds")
mpsz
```

### 16.5.1 Converting from sf data.table to SpatialPolygonsDataFrame

There are at least two ways to compute the required distance matrix. One is based on **sf** and the other is based on **sp**. Past experience shown that computing distance matrix by using **sf** function took a relatively longer time than the **sp** method, especially when the data set is large. In view of this, the **sp** method is used in the code chunks below.

The `as()` function with "Class" argument set as "Spatial" is used to convert `mpsz` from sf tibble data frame to SpatialPolygonsDataFrame of **sp** object

> ***Student Note***: For SpatialPolygonsDataFrame, in order to select a variable within a data.frame within the object, we will need to use something like mpsz\@data\$var_name.

```{r}
mpsz_sp = as(mpsz, "Spatial")
mpsz_sp
```

### 16.5.2 Computing the Distance Matrix

The `spDists()` function in the **sp** package is used to compute the Euclidean distance between the centroids of the planning subzones.

> ***Student Note***: Calculating the distance between centroids is computationally less intensive compared to more detailed spatial analyses. However, using centroid-to-centroid distance is a simplification and may not always capture the full complexity of spatial relationships.

Notice that the output `dist` is a matrix object class of R. Also, notice that the column headers and row headers are not labeled with the planning subzone codes.

> ***Student Note***:
>
> -   If longlat = TRUE, longitude and latitude are used to calculate the distance.
>
> -   `dist` is a matrix 332 by 332 (based on 332 observations from `mpsz`).

```{r}
dist = spDists(mpsz_sp, 
                longlat = FALSE)
head(dist, n=c(10, 10))
```

### 16.5.3 Labelling Column and Row Headers of a Distance Matrix

A list sorted according to the the distance matrix by planning sub-zone code is created to hold the sub-zone codes.

```{r}
sz_names = mpsz$SUBZONE_C
```

Next, the sub-zone codes are attached to row and column to facilitate distance matrix matching later on.

```{r}
colnames(dist) = paste0(sz_names)
rownames(dist) = paste0(sz_names)
```

### 16.5.4 Pivoting Distance Value by SUBZONE_C

Next, the distance matrix is pivoted into a long table by using the row and column subzone codes.

Note that the within zone (i.e., when Var1 and Var2 are the same) distance is 0.

> ***Student Note***: Do not use code to sort the data, otherwise the sequence will be messed up.

```{r}
distPair = melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

### 16.5.5 Updating Intra-zonal Distances

A constant value is then used to replace the intra-zonal distance of 0.

The minimum value of the inter-zonal distance is derived using the `summary()` function. The value is 173.8. Hence, by quick estimation, an intra-zonal distance proxy value of less than half of 173.8 would be appropriate.

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

Hence, a constant distance value of 50m is added as the intra-zonal distance. The resulting data.frame is checked using the `summary()` function, showing that the minimum distance is now 50m.

```{r}
distPair$dist = ifelse(distPair$dist == 0,
                        50, distPair$dist)

distPair %>%
  summary()
```

The origin (Var1) and destination (Var2) fields are renamed, and the output is saved as in rds format for future use.

```{r}
distPair = distPair %>%
  rename(orig = Var1,
         dest = Var2)

write_rds(distPair, "data/rds/distPair.rds") 
```

## 16.6 Preparing Flow Data

The code chunk below is used import the `od_data`.

```{r}
od_data = read_rds("data/rds/od_data.rds")
```

The total passenger trip between and within planning subzones is computed using `group_by()` and `summarise()` functions in the **dplyr** package. The output is all `flow_data`, which is shown below using the `head()` function.

```{r}
flow_data = od_data %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>% 
  summarize(TRIPS = sum(MORNING_PEAK)) 

head(flow_data, 10)
```

### 16.6.1 Separating Intra-flow from Passenger Volume data.frame

A new field, "FlowNoIntra", is created to either hold the value 0 if there was an intra-zonal flow, or hold the value of the number of inter-zonal trips.

Another new field, "offset", is created to hold the value of 0.000001 if there was intra-zonal flow, or hold the value of 1 if there was no inter-zonal flow.

```{r}
flow_data$FlowNoIntra = ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0, flow_data$TRIPS)

flow_data$offset = ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 
  0.000001, 1)
```

### 16.6.2 Combining Passenger Volume Data with Distance Value

The data value type of "ORINGIN_SZ" and "DESTIN_SZ" in the flow_data are converted to factor data type.

```{r}
flow_data$ORIGIN_SZ = as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ = as.factor(flow_data$DESTIN_SZ)
```

Then, the `left_join()` function in the **dplyr** package is used to combine the `flow_data` data.frame and the `distPair` data.frame. The output is `flow_data1`.

```{r}
flow_data1 = flow_data %>%
  left_join (distPair,
             by = c("ORIGIN_SZ" = "orig",
                    "DESTIN_SZ" = "dest"))
```

## 16.7 Preparing Origin and Destination Attributes

### 16.7.1 Importing Population Data

The pre-prepared population data by planning sub-zone is imported using the `read_csv()` function in the **readr** package as `pop`, which is a sf tibble data.frame. It divides the population into three age groups: ages 7-12, 13-24, and 25-64.

```{r}
pop = read_csv("data/aspatial/pop.csv")
```

### 16.7.2 Geospatial Data Wrangling

The `pop` data.frame is then joined with the `mpsz` data.frame. The relevant columns are selected, and two are renamed.

```{r}
pop = pop %>%
  left_join(mpsz,
            by = c("PA" = "PLN_AREA_N",
                   "SZ" = "SUBZONE_N")) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)
```

### 16.7.3 Preparing Origin Attribute

The origin attribute is then prepared by combining `flow_data1` and `pop` by matching "ORIGIN_SZ" to "SZ"

```{r}
flow_data1 = flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = "SZ")) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

### 16.7.4 Preparing Destination Attribute

The destination attribute is then prepared by combining `flow_data1` and `pop` by matching "DESTIN_SZ" to "SZ"

```{r}
flow_data1 = flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = "SZ")) %>%
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

The output data file is then saved as `SIM_data` in rds data file format.

```{r}
write_rds(flow_data1, "data/rds/SIM_data")
```

## 16.8 Calibrating Spatial Interaction Models

SIMs are calibrated using Poisson Regression methods below.

### 16.8.1 Importing the Modelling Data

The modelling data in rds file format is first imported.

```{r}
SIM_data = read_rds("data/rds/SIM_data.rds")
```

### 16.8.2 Visualising the Dependent Variable

Then, the distribution of the dependent variable (i.e. "TRIPS") is plotted by using the histogram method.

The historgram shows that the distribution is highly skewed and does not resemble normal distribution.

```{r}
ggplot(data = SIM_data,
       aes(x = TRIPS)) +
  geom_histogram()
```

The relation between the dependent variable and one of the key independent variable in SIM, namely distance is then visualised using the scatterplot method.

The scatterplot shows that their relationship hardly resembles a linear relationship.

```{r}
ggplot(data = SIM_data,
       aes(x = dist,
           y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)
```

However, if the log transformed version of both variables are plotted, the result better resembles a linear relationship.

```{r}
ggplot(data = SIM_data,
       aes(x = log(dist),
           y = log(TRIPS))) +
  geom_point() +
  geom_smooth(method = lm)
```

### 16.8.3 Checking for Variables with Zero Values

Since Poisson Regression is based on log transformation, and log 0 is undefined, it is important for us to ensure that there are no zero values in the explanatory variables.

The `summary()` function is used to compute the summary statistics of all variables in `SIM_data` data.frame. This revealed that the variables "ORIGIN_AGE7_12", "ORIGIN_AGE13_24", "ORIGIN_AGE25_64", "DESTIN_AGE7_12", "DESTIN_AGE13_24", "DESTIN_AGE25_64" have zero values.

```{r}
summary(SIM_data)
```

In view of this, these zero values are replaced with the value of 0.99.

```{r}
SIM_data$DESTIN_AGE7_12 = ifelse(
  SIM_data$DESTIN_AGE7_12 == 0,
  0.99, SIM_data$DESTIN_AGE7_12)
SIM_data$DESTIN_AGE13_24 = ifelse(
  SIM_data$DESTIN_AGE13_24 == 0,
  0.99, SIM_data$DESTIN_AGE13_24)
SIM_data$DESTIN_AGE25_64 = ifelse(
  SIM_data$DESTIN_AGE25_64 == 0,
  0.99, SIM_data$DESTIN_AGE25_64)
SIM_data$ORIGIN_AGE7_12 = ifelse(
  SIM_data$ORIGIN_AGE7_12 == 0,
  0.99, SIM_data$ORIGIN_AGE7_12)
SIM_data$ORIGIN_AGE13_24 = ifelse(
  SIM_data$ORIGIN_AGE13_24 == 0,
  0.99, SIM_data$ORIGIN_AGE13_24)
SIM_data$ORIGIN_AGE25_64 = ifelse(
  SIM_data$ORIGIN_AGE25_64 == 0,
  0.99, SIM_data$ORIGIN_AGE25_64)

summary(SIM_data)
```

### 16.8.4 Unconstrained Spatial Interaction Model

An unconstrained SIM is calibrated below by using the `glm()` function of the **stats** package. The explanatory variables are origin population by different age cohorts (e.g., "ORIGIN_AGE25_64"), destination population by different age cohorts (e.g., "DESTIN_AGE25_64"), and the distance between the origin and destination in km (i.e., "dist").

```{r}
uncSIM = glm(formula = TRIPS ~ 
                log(ORIGIN_AGE25_64) + 
                log(DESTIN_AGE25_64) +
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
uncSIM
```

### 16.8.5 R-squared Function

The R-Squared value is calculated to measure how much variation of the trips can be accounted by the unconstrained SIM.

```{r}
CalcRSquared = function(observed, estimated){
  r = cor(observed, estimated)
  R2 = r^2
  R2
}

CalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)

r2_mcfadden(uncSIM)
```

### 16.8.6 Origin (Production) Constrained Spatial Interaction Model

An origin constrained SIM is fitted.

```{r}
orcSIM = glm(formula = TRIPS ~ 
                 ORIGIN_SZ +
                 log(DESTIN_AGE25_64) +
                 log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(orcSIM)
```

The R-squared value is then calculated to examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)
```

### 16.8.7 Destination Constrained Spatial Interaction Model

A destination constrained SIM is fitted.

```{r}
decSIM = glm(formula = TRIPS ~ 
                DESTIN_SZ + 
                log(ORIGIN_AGE25_64) + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(decSIM)
```

The R-squared value is then calculated to examine how the constraints hold for destinations this time.

```{r}
CalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)
```

### 16.8.8 Doubly Constrained Spatial Interaction Model

A doubly constrained SIM is fitted.

```{r}
dbcSIM = glm(formula = TRIPS ~ 
                ORIGIN_SZ + 
                DESTIN_SZ + 
                log(dist),
              family = poisson(link = "log"),
              data = SIM_data,
              na.action = na.exclude)
summary(dbcSIM)
```

The R-squared value is then calculated to examine how the constraints hold for destinations this time.

Note that there is a relatively greater improvement in the R-squared value.

```{r}
CalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)
```

### 16.8.9 Model Comparison

Another useful model performance measure for continuous dependent variable is the Root Mean Squared Error. The `compare_performance()` in the **performance** package is used to compare the different models.

A list called `model_list` is created to hold the four models.

```{r}
model_list = list(unconstrained=uncSIM,
                   originConstrained=orcSIM,
                   destinationConstrained=decSIM,
                   doublyConstrained=dbcSIM)
```

The RMSE of the models are computed using the compare_performance() function. The output reveals that doubly constrained SIM is the best model among the four SIMs because it has the smallest RMSE value of 1487.111.

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```

### 16.8.10 Visualising Fitted Values

The observed values and the fitted values are visualised below.

The fitted values from each model are extracted.

```{r}
df = as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0)
```

The values are then joined to the `SIM_data` data.frame.

```{r}
SIM_data = SIM_data %>%
  cbind(df) %>%
  rename(uncTRIPS = "uncSIM$fitted.values")
```

The same steps are repeated for the three other SIMs - Origin Constrained SIM (i.e. `orcSIM`), Destination Constrained SIM (i.e. `decSIM`), and Doubly Constrained SIM (i.e. `dbcSIM`).

```{r}
df = as.data.frame(orcSIM$fitted.values) %>%
  round(digits = 0)

SIM_data = SIM_data %>%
  cbind(df) %>%
  rename(orcTRIPS = "orcSIM$fitted.values")

df = as.data.frame(decSIM$fitted.values) %>%
  round(digits = 0)

SIM_data = SIM_data %>%
  cbind(df) %>%
  rename(decTRIPS = "decSIM$fitted.values")

df = as.data.frame(dbcSIM$fitted.values) %>%
  round(digits = 0)

SIM_data = SIM_data %>%
  cbind(df) %>%
  rename(dbcTRIPS = "dbcSIM$fitted.values")

```

The plots are then visualised below:

```{r}
unc_p = ggplot(data = SIM_data,
                aes(x = uncTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

orc_p = ggplot(data = SIM_data,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p = ggplot(data = SIM_data,
                aes(x = decTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p = ggplot(data = SIM_data,
                aes(x = dbcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```

[**\~\~\~ End of In-class Exercise 3 \~\~\~**]{.smallcaps}
