---
title: "In-class Exercise 3"
date: "2 December 2023"
date-modified: "last-modified" #allows for updating to the latest date
format: html
execute: 
  echo: true #shows the code
  eval: true #shows the outcomes of the code
  warning: false #does not show the warnings
editor: visual
background-color: lightgrey;
font-family:  Palatino Linotype;
---

# 16 Calibrating Spatial Interaction Models with R

## 16.1 Overview

Spatial Interaction Models (SIMs) are mathematical models for estimating flows between spatial entities developed by Alan Wilson in the late 1960s and early 1970, with considerable uptake and refinement for transport modelling since then Boyce and Williams (2015).

There are four main types of traditional SIMs (Wilson 1971):

-   Unconstrained

-   Production-constrained

-   Attraction-constrained

-   Doubly-constrained

Ordinary least square (OLS), log-normal, Poisson and negative binomial (NB) regression methods have been used extensively to calibrate OD flow models by processing flow data as different types of dependent variables. In this chapter, you will gain hands-on experiences on using appropriate R packages to calibrate SIM by using there four regression methods.

***Note***: Calibration is the process of adjusting parameters in the model to try and get the estimates to agree with the observed data as much as possible. Adjusting the parameters is the sort of iterative process that computers are particularly good at and the goodness-of-fit statistics can be used to indicate when the optimum solution is found. Historically this process required a researcher with the requisite programming skills to write a computer algorithm to iteratively adjust each parameter, check the goodness-of-fit, and then start all over again until the goodness-of-fit statistic was maximised/minimised. (Adam Dennett, 2018)

## 16.2 The Case Study and Data

In this exercise, we are going to calibrate SIM to determine factors affecting the public bus passenger flows during the morning peak in Singapore.

## 16.3 Getting Started

For the purpose of this exercise, four r packages will be used. They are:

-   **sf** for importing, integrating, processing and transforming geospatial data.

-   **tidyverse** for importing, integrating, wrangling and visualising data.

-   **tmap** for creating thematic maps.

-   **sp** handles spatial data (efficient in terms of computation).

-   **performance** provides utilities for computing measures to assess model quality,

-   **reshape2** handles matrix format (predecessor of tidyr).

-   **ggpubr** for publication ready plots.

```{r}
pacman::p_load(tmap, sf, sp, DT,
               performance, reshape2,
               ggpubr, tidyverse)
```

## 16.4 The Data

This exercise is a continuation of **Chapter 15: Processing and Visualising Flow Data** and the following data will be used:

-   *od_data.rds*, weekday morning peak passenger flows at planning subzone level.

-   *mpsz.rds*, URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.

Beside these two data sets, an additional attribute data file called pop.csv will be provided.

## 16.5 Computing Distance Matrix

In spatial interaction, a distance matrix is a table that shows the distance between pairs of locations. For example, in the table below we can see an Euclidean distance of 3926.0025 between MESZ01 and RVSZ05, of 3939.1079 between MESZ01 and SRSZ01, and so on. By definition, an location\'s distance from itself, which is shown in the main diagonal of the table, is 0.

In this section, we will compute a distance matrix by using URA Master Plan 2019 Planning Subzone boundary in which you saved as an rds file called *mpsz*.

First, let us import *mpsz.rds* into R environemnt by using the code chunk below. This is a sf tibble dataframe object class.

```{r}
mpsz = read_rds("data/rds/mpsz.rds")
mpsz
```

### 16.5.1 Converting from sf data.table to SpatialPolygonsDataFrame

There are at least two ways to compute the required distance matrix. One is based on sf and the other is based on sp. Past experience shown that computing distance matrix by using sf function took relatively longer time that sp method especially the data set is large. In view of this, sp method is used in the code chunks below.

First `as.Spatial()` will be used to convert *mpsz* from sf tibble data frame to SpatialPolygonsDataFrame of sp object as shown in the code chunk below.

> ***Student Note***: For SpatialPolygonsDataFrame, in order to select a variable within a dataframe within the object, we will need to use something like mpsz\@data\$var_name.

```{r}
mpsz_sp = as(mpsz, "Spatial")
mpsz_sp
```

### 16.5.2 Computing the Distance Matrix

Next, `spDists()` of **sp** package will be used to compute the Euclidean distance between the centroids of the planning subzones.

> ***Student Note***: Using centroid-to-centroid distance is a simplification and may not always capture the full complexity of spatial relationships. Calculating the distance between centroids is computationally less intensive compared to more detailed spatial analyses.

Notice that the output *dist* is a matrix object class of R. Also notice that the column heanders and row headers are not labeled with the planning subzone codes.

> ***Student Note***: If longlat = TRUE, longitude and latitude are used to calculate the distance.
>
> dist is a matrix 332 by 332 (from mpsz 332 observations).

```{r}
dist = spDists(mpsz_sp, 
                longlat = FALSE)
head(dist, n=c(10, 10))
```

### 16.5.3 Labelling Column and Row Headers of a Distance Matrix

First, a list sorted according to the the distance matrix by planning sub-zone code is created.

```{r}
sz_names = mpsz$SUBZONE_C
```

Next, the `SUBZONE_C` is attached to row and column for distance matrix matching ahead

```{r}
colnames(dist) = paste0(sz_names)
rownames(dist) = paste0(sz_names)
```

### 16.5.4 Pivoting Distance Value by SUBZONE_C

Next, we will pivot the distance matrix into a long table by using the row and column subzone codes as show in the code chunk below.

Notice that the within zone distance is 0.

```{r}
distPair = melt(dist) %>%
  rename(dist = value)
head(distPair, 10)
```

### 16.5.5 Updating Intra-zonal Distances

In this section, we are going to append a constant value to replace the intra-zonal distance of 0.

First, we will select and find out the minimum value of the distance by using `summary()`.

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

Next, a constant distance value of 50m is added into intra-zones distance.

```{r}
distPair$dist = ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

The code chunk below will be used to check the result data.frame.

```{r}
distPair %>%
  summary()
```

The code chunk below is used to rename the origin and destination fields.

```{r}
distPair = distPair %>%
  rename(orig = Var1,
         dest = Var2)
```

Lastly, the code chunk below is used to save the dataframe for future use.

```{r}
write_rds(distPair, "data/rds/distPair.rds") 
```

## 16.6 Preparing Flow Data

### 16.6.1 Separating Intra-flow from Passenger Volume df

### 

### 16.6.2 Combining Passenger Volume Data with Distance Value

## 16.7 Preparing Origin and Destination Attributes

### 16.7.1 Importing Population Data

### 16.7.2 Geospatial Data Wrangling

### 16.7.3 Preparing Origin Attribute

### 16.7.4 Preparing Destination Attribute

## 16.8 Calibrating Spatial Interaction Models

### 16.8.1 Importing the Modelling Data

### 16.8.2 Visualising the Dependent Variable

### 16.8.3 Checking for Variables with Zero Values

### 16.8.4 Unconstrained Spatial Interaction Model

### 16.8.5 R-squared Function

### 

### 16.8.6 Origin (Production) Constrained Spatial Interaction Model

### 

### 16.8.7 Destination Constrained Spatial Interaction Model

### 

### 16.8.8 Doubly Constrained Spatial Interaction Model

### 

### 16.8.9 Model Comparison

### 

### 16.8.10 Visualising Fitted Values

### 

[**\~\~\~ End of In-class Exercise 3 \~\~\~**]{.smallcaps}
