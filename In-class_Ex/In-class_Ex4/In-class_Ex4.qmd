---
title: "In-class Exercise 4"
date: "9 December 2023"
date-modified: "last-modified" #allows for updating to the latest date
format: html
execute: 
  echo: true #shows the code
  eval: true #shows the outcomes of the code
  warning: false #does not show the warnings
editor: visual
background-color: lightgrey;
font-family:  Palatino Linotype;
---

# In-class Exercise 4: Geospatial Data Science with R

## 1 Overview

A well calibrated Spatial Interaction Model (SIM) requires conceptually logical and well-prepared propulsiveness and attractiveness variables.

In this in-class exercise, the tasks are:

-   Perform geocoding using SLA OneMap API;

-   Convert an aspatial data set into a simple feature tibble data.frame;

-   Perform point-in-polygon count analysis;

-   Append the propulsiveness and attractiveness variables onto a flow data set; and

-   Calibrate Geographically Weighted Poisson Regression models.

## 2 Getting Started

The following packages are loaded into the R environment:

-   **sf** for importing, managing, and processing geospatial data;

-   **tidyverse** (i.e.Â readr, tidyr, dplyr) for performing data science tasks such as importing, tidying, and wrangling data;

-   **tmap** for thematic mapping; and

-   **httr** for making HTTP requests.

```{r}
pacman::p_load(tidyverse, sf, httr, tmap)
```

## 3 Geocoding with SLA API

The data set, *Generalinformationofschools.csv*, is downloaded from Data.gov.sg.

Geocoding is the process of taking an aspatial description of a location, such as an address or postcode, and returning geographic coordinates, frequently latitude-longitude pair, to identify a location on the Earth's surface.

The Singapore Land Authority (SLA) supports an online geocoding service called OneMap API. The Search API looks up the address data or 6-digit postal code for an entered value. It then returns both latitude, longitude and x,y coordinates of the searched location.

The code chunks below perform geocoding using SLA OneMap API. The input data is in csv file format, and imported into the R environment using the `read_csv()` function in the **readr** package. A collection of http call functions in the **httr** package is then used to pass the individual records to the geocoding server on OneMap.

The output is two tibble data.frames - `found` and `not_found`. The `found` data.frame contains all records that are geocoded correctly, and the `not_found` data.frame contains postal code(s) that fail to be geocoded.

The `found` data table is joined with the original csv data table using a unique identifier (i.e. POSTAL) that is common to both data tables. The output data table is saved as a csv file, `found`.

```{r}
url = "https://www.onemap.gov.sg/api/common/elastic/search"

csv = read_csv("data/aspatial/Generalinformationofschools.csv")
postcodes = csv$`postal_code`

found = data.frame()
not_found = data.frame()

for(postcode in postcodes){
  query = list('searchVal' = postcode, 'returnGeom' = 'Y', 'getAddrDetails' = 'Y', 'pageNum' = '1')
  res = GET(url, query = query)
  if((content(res)$found)!=0){
  found = rbind(found, data.frame(content(res))[4:13])
  } else{
  not_found = data.frame(postcode)
  }
}
```

Next, both the `found` and `not_found` data.frames are combined into a single tibble data.frame, `merged`. At the same time, `merged` and `not_found` tibble data.frames are written into two separate csv files, *schools* and *not_found* respectively.

```{r}
merged = merge(csv, found, by.x = 'postal_code', by.y = 'results.POSTAL', all = TRUE)
write.csv(merged, file = 'data/aspatial/schools.csv')
write.csv(not_found, file = 'data/aspatial/not_found.csv')
```

## 4 Converting Aspatial Data into simple feature tibble data.frame

### 4.1 Tidying *schools* Data Frame

In this sub-section, the schools.csv is imported into the R environment and only the necessary fields are selected and renamed.

```{r}
schools = read_csv('data/aspatial/schools.csv') %>%
  rename(latitude = "results.LATITUDE", 
         longitude = "results.LONGITUDE") %>%
  select(postal_code, school_name, latitude, longitude)
```

> ***Student Note***: Using Google Map, the latitude and longitude of the school (Zhenghua Secondary School) that was not geocoded are 1.389279 and 103.7651 respectively. This is manually coded into the schools data frame.

```{r}
schools = schools %>%
  mutate(latitude = ifelse(school_name == "ZHENGHUA SECONDARY SCHOOL", 1.389279, latitude)) %>%
  mutate(longitude = ifelse(school_name == "ZHENGHUA SECONDARY SCHOOL", 103.7651, longitude))
```

### 4.2 Converting Aspatial Data into Simple Feature Tibble Data Frame

Next, the schools tibble data.frame is converted into a simple feature tibble data.frame, schools_sf, using the `st_as_sf()` function in the **sf** package and the values in the latitude and longitude fields.

```{r}
schools_sf = st_as_sf(schools,
                      coords = c("longitude", "latitude"),
                      crs = 4326) %>%
  st_transform(crs = 3414)
```

### 4.3 Plotting A Point Simple Feature Layer

To ensure that the *schools* sf tibble data.frame has been projected and converted correctly, the schools point data are plotted for visual inspection.

First, the Master Plan Subzone Boundary shapefile is imported as the `mpsz` sf tibble data.frame.

```{r}
mpsz = st_read(dsn = "data/geospatial/",
                layer = "MPSZ-2019") %>%
  st_transform(crs = 3414)
```

A point symbol map is then plotted to show the locations of the schools.

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(mpsz) +
  tm_polygons() +
tm_shape(schools_sf) +
  tm_dots()
```

### 4.4 Performing Point-in-Polygon Count for Schools

The number of schools in each planning subzone is then counted using the `lengths()` function in the **base** pacakge and the `st_intersects()` function in the **sf** package.

The summary statistics reveal that there are excessive 0 values in "SCHOOL_COUNT" field. If the `log()` function is used to transform this field, these 0 values would need to be replaced with a value between 0 and 1 (exclusive).

```{r}
mpsz$`SCHOOL_COUNT` = lengths(
  st_intersects(mpsz, schools_sf)
)

summary(mpsz$SCHOOL_COUNT)
```

## 5 Data Integration and Final Touch-Up

### 5.1 Performing Point-in-Polygon Count for Businesses

The number of business locations are also counted for each planning subzone using the same steps earlier.

```{r}
biz_sf = st_read(dsn = "data/geospatial",
                 layer = "Business")
```

The points are visualised.

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(mpsz) +
  tm_polygons() +
tm_shape(biz_sf) +
  tm_dots()
```

Again, the summary statistics show that there are 0 values.

```{r}
mpsz$`BIZ_COUNT` = lengths(
  st_intersects(
    mpsz, biz_sf))

summary(mpsz$BIZ_COUNT)
```

### 5.2 Performing Join to Incorporate Counts of Schools and Businesses

The origin-destination bus passengers flow data is imported

```{r}
flow_data = read_rds("data/rds/flow_data.rds")
```

The derived fields of "SCHOOL_COUNT" and "BIZ_COUNT" are added to the `flow_data` sf tibble data.frame.

> ***Student Note***: The unique join fields are "DESTIN_SZ" of `flow_data` and SUBZONE_C of `mpsz_tidy` because the "SCHOOL_COUNT" and "BIZ_COUNT" values are pull factors that attract bus commuters to the destinations.

```{r}
mpsz_tidy = mpsz %>%
  st_drop_geometry() %>%
  select(SUBZONE_C, SCHOOL_COUNT, BIZ_COUNT)
```

```{r}
flow_data = flow_data %>%
  left_join(mpsz_tidy,
            by = c("DESTIN_SZ" = "SUBZONE_C")) %>%
  rename(TRIPS = MORNING_PEAK,
         DIST = dist)
```

### 5.3 Checking for and Replacing Variables with Zero Values

Since the Poisson Regression is based off log, and log 0 is undefined, it is important to ensure that there are no 0 values in the explanatory variables.

The `summary()` function in the base package is used to compute the summary statistics of all variables. As mentioned earlier, the "SCHOOL_COUNT" and "BIZ_COUNT" variables consist of 0 values.

```{r}
summary(flow_data)
```

The 0 values are replaced with 0.99.

```{r}
flow_data$SCHOOL_COUNT = ifelse(
  flow_data$SCHOOL_COUNT == 0,
  0.99, flow_data$SCHOOL_COUNT)
flow_data$BIZ_COUNT = ifelse(
  flow_data$BIZ_COUNT == 0,
  0.99, flow_data$BIZ_COUNT)
```

The summary() function in the base package is used again to check that the replacements are been made.

```{r}
summary(flow_data)
```

The tidied flow_data is then saved into an rds file, `flow_data_tidy`.

```{r}
write_rds(flow_data,
          "data/rds/flow_data_tidy.rds")
```

------------------------------------------------------------------------

## 6 Calibrating Spatial Interaction Models

### 6.1 Preparation

The required packages are loaded.

```{r}
pacman::p_load(tmap, sf, performance,
               ggpubr, tidyverse)
```

The earlier prepared `flow_data_tidy` is imported.

```{r}
flow_data = read_rds("data/rds/flow_data_tidy.rds")
```

```{r}
glimpse(flow_data)
```

The intra-subzone flows are filtered away.

```{r}
flow_data$FlowNoIntra = ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ,
  0, flow_data$TRIPS)

flow_data$offset = ifelse(
  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ,
  0.000001, 1)
```

```{r}
inter_zonal_flow = flow_data %>%
  filter(FlowNoIntra > 0)
```

### 6.2 Unconstrained Spatial Interaction Model

```{r}
uncSIM_Poisson = glm(formula = TRIPS ~ 
               log(ORIGIN_AGE7_12) +
               log(ORIGIN_AGE13_24) +
               log(ORIGIN_AGE25_64) +
               log(DESTIN_AGE7_12) +
               log(DESTIN_AGE13_24) +
               log(DESTIN_AGE25_64) +
               log(SCHOOL_COUNT) +
               log(BIZ_COUNT) + 
               log(DIST),
             family = poisson(link = "log"),
             data = inter_zonal_flow,
             na.action = na.exclude)

summary(uncSIM_Poisson)
```

### 6.3 Origin (Production) Constrained Spatial Interaction Model

```{r}
orcSIM_Poisson = glm(formula = TRIPS ~
                       ORIGIN_SZ +
                       log(SCHOOL_COUNT) +
                       log(BIZ_COUNT) +
                       log(DIST) -1, # no need for intercept for origin/dest constrained
                     family = poisson(link = "log"),
                     data = inter_zonal_flow,
                     na.action = na.exclude)

options(max.print=10000) 
summary(orcSIM_Poisson)
```

```{r}
CalcRSquared = function(observed, estimated){
  r = cor(observed, estimated)
  R2 = r^2
  R2
}
```

The calculated R-squared value shows how well the factors explain the flow.

```{r}
CalcRSquared(orcSIM_Poisson$data$TRIPS, orcSIM_Poisson$fitted.values)
```

The RMSE (root mean square error) shows how much error the model typically makes in its predictions, with a higher weight for large errors.Â 

```{r}
performance_rmse(orcSIM_Poisson,
                 normalized = FALSE) # use raw values (not normalised to mean = 0, sd = 1)
```

```{r}
performance_rmse(orcSIM_Poisson,
                 normalized = TRUE)
```

### 6.4 Destination Constrained Spatial Interaction Model

```{r}
decSIM_Poisson = glm(formula = TRIPS ~
                       DESTIN_SZ +
                       log(SCHOOL_COUNT) +
                       log(BIZ_COUNT) +
                       log(DIST) -1, # no need for intercept for origin/dest constrained
                     family = poisson(link = "log"),
                     data = inter_zonal_flow,
                     na.action = na.exclude)

options(max.print=10000) 
summary(decSIM_Poisson)
```

### 6.5 Doubly Constrained Spatial Interaction Model

```{r}
dbcSIM_Poisson = glm(formula = TRIPS ~
                       ORIGIN_SZ +
                       DESTIN_SZ +
                       log(DIST), # note: -1 not required for doubly constrained SIM
                     family = poisson(link = "log"),
                     data = inter_zonal_flow,
                     na.action = na.exclude)
options(max.print=10000) 
summary(dbcSIM_Poisson)
```

### 6.6 Model Comparison

```{r}
model_list = list(unconstrained = uncSIM_Poisson,
                  originConstrained = orcSIM_Poisson,
                  destinationConstrained = decSIM_Poisson,
                  doublyconstrained = dbcSIM_Poisson)
```

```{r}
compare_performance(model_list,
                    metrics = "RMSE")
```

The print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 1906.694.

[**\~\~\~ End of In-class Exercise 4 \~\~\~**]{.smallcaps}
